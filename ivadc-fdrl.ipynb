{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":5835006,"sourceType":"datasetVersion","datasetId":3354128}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Install necessary libraries\n# !pip install torch torchvision matplotlib opencv-python tqdm gym numpy\n\n# Import required libraries\nimport os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nimport torchvision.models as models\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision.ops import nms\nimport numpy as np\nimport cv2\nfrom PIL import Image\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport random\nimport glob\nimport gym\nfrom collections import deque","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-03T14:37:34.659669Z","iopub.execute_input":"2025-02-03T14:37:34.660003Z","iopub.status.idle":"2025-02-03T14:37:34.665187Z","shell.execute_reply.started":"2025-02-03T14:37:34.659969Z","shell.execute_reply":"2025-02-03T14:37:34.664138Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"class UCSDAnomalyDataset(Dataset):\n    def __init__(self, root_dir, transform=None):\n        self.root_dir = root_dir\n        self.transform = transform\n        self.image_paths = sorted(glob.glob(os.path.join(root_dir, \"Test*/\", \"*.tif\")))  # Load all test folders\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        img_path = self.image_paths[idx]\n        image = Image.open(img_path).convert(\"L\")  # Convert to grayscale\n        if self.transform:\n            image = self.transform(image)\n        return image, img_path\n\n# Define transformations\ntransform = transforms.Compose([\n    transforms.Resize((256, 256)),  \n    transforms.ToTensor(),          \n    transforms.Normalize(mean=[0.5], std=[0.5])  \n])\n\n# Load dataset (All test files)\ndataset_path = \"/kaggle/input/ucsd-anomaly-detection-dataset/UCSD_Anomaly_Dataset.v1p2/UCSDped2/Test\"\ndataset = UCSDAnomalyDataset(root_dir=dataset_path, transform=transform)\ndataloader = DataLoader(dataset, batch_size=500, shuffle=False, num_workers=4)\n\nprint(f\"Loaded dataset with {len(dataset)} frames from all test files\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T14:37:34.666331Z","iopub.execute_input":"2025-02-03T14:37:34.666617Z","iopub.status.idle":"2025-02-03T14:37:34.742450Z","shell.execute_reply.started":"2025-02-03T14:37:34.666594Z","shell.execute_reply":"2025-02-03T14:37:34.741694Z"}},"outputs":[{"name":"stdout","text":"Loaded dataset with 2010 frames from all test files\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# Feature extraction\nresnet = models.resnet152(pretrained=True)\nresnet.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\nfeature_extractor = nn.Sequential(*list(resnet.children())[:-2])\nfeature_extractor.eval()\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nfeature_extractor = feature_extractor.to(device)\n\ndef extract_features(images):\n    images = images.to(device)\n    with torch.no_grad():\n        features = feature_extractor(images)\n    return features\n# ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T14:37:34.743982Z","iopub.execute_input":"2025-02-03T14:37:34.744201Z","iopub.status.idle":"2025-02-03T14:37:36.125796Z","shell.execute_reply.started":"2025-02-03T14:37:34.744183Z","shell.execute_reply":"2025-02-03T14:37:36.125060Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# region proposal network\nclass RPN(nn.Module):\n    def __init__(self, in_channels=2048, mid_channels=512, num_anchors=9):\n        super(RPN, self).__init__()\n        self.conv = nn.Conv2d(in_channels, mid_channels, kernel_size=3, stride=1, padding=1)\n        self.relu = nn.ReLU()\n        self.cls_logits = nn.Conv2d(mid_channels, num_anchors * 2, kernel_size=1)  \n        self.bbox_pred = nn.Conv2d(mid_channels, num_anchors * 4, kernel_size=1)  \n\n    def forward(self, x):\n        x = self.relu(self.conv(x))\n        logits = self.cls_logits(x)\n        bbox_preds = self.bbox_pred(x)\n        return logits, bbox_preds\n\nrpn = RPN().to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T14:37:36.127090Z","iopub.execute_input":"2025-02-03T14:37:36.127329Z","iopub.status.idle":"2025-02-03T14:37:36.205919Z","shell.execute_reply.started":"2025-02-03T14:37:36.127308Z","shell.execute_reply":"2025-02-03T14:37:36.204678Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"class DQN(nn.Module):\n    def __init__(self, input_size=2048 * 8 * 8, output_size=2):  # Fix input size\n        super(DQN, self).__init__()\n        self.fc1 = nn.Linear(input_size, 256)\n        self.fc2 = nn.Linear(256, 128)\n        self.fc3 = nn.Linear(128, output_size)\n\n    def forward(self, x):\n        x = torch.relu(self.fc1(x))\n        x = torch.relu(self.fc2(x))\n        return self.fc3(x)\n\n# Initialize DQN with the correct input size\ndqn = DQN(input_size=2048 * 8 * 8, output_size=2).to(device)\n\n\noptimizer_dqn = optim.Adam(dqn.parameters(), lr=0.001)\ncriterion_dqn = nn.MSELoss()\nreplay_memory = deque(maxlen=10000)\n\ngamma = 0.95  \nepsilon = 1.0  \nepsilon_min = 0.01  \nepsilon_decay = 0.995  \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T14:37:36.207425Z","iopub.execute_input":"2025-02-03T14:37:36.207719Z","iopub.status.idle":"2025-02-03T14:37:36.473845Z","shell.execute_reply.started":"2025-02-03T14:37:36.207687Z","shell.execute_reply":"2025-02-03T14:37:36.472391Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"def train_rpn_dqn():\n    rpn.train()\n    dqn.train()\n\n    optimizer_rpn = optim.SGD(rpn.parameters(), lr=0.05, momentum=0.9)\n    optimizer_dqn = optim.Adam(dqn.parameters(), lr=0.001)\n\n    criterion_dqn = nn.MSELoss()  # Ensure loss function is properly defined\n\n    for epoch in range(15):  \n        epoch_loss_rpn = 0\n        epoch_loss_dqn = 0\n        correct_rpn = 0\n        total_rpn = 0\n        correct_dqn = 0\n        total_dqn = 0\n\n        for images, _ in tqdm(dataloader, desc=f\"Epoch {epoch + 1}/15\"):\n            images = images.to(device)\n            features = extract_features(images)\n\n            # === RPN Forward Pass ===\n            logits, bbox_preds = rpn(features)  \n            batch_size, num_anchors_x2, H, W = logits.shape\n            num_anchors = num_anchors_x2 // 2  \n\n            # Generate Random Targets (For Testing)\n            targets_cls = torch.randint(0, 2, (batch_size, num_anchors, H, W), device=device)  \n            targets_bbox = torch.randn_like(bbox_preds, device=device)  \n\n            logits = logits.permute(0, 2, 3, 1).reshape(-1, 2)  \n            targets_cls = targets_cls.permute(0, 2, 3, 1).reshape(-1).long()  \n\n            # Compute RPN Loss\n            cls_loss = nn.CrossEntropyLoss()(logits, targets_cls)  \n            bbox_loss = nn.SmoothL1Loss()(bbox_preds, targets_bbox)\n            loss_rpn = cls_loss + bbox_loss\n\n            optimizer_rpn.zero_grad()  # \n            loss_rpn.backward()\n            optimizer_rpn.step()\n            \n            epoch_loss_rpn += loss_rpn.item()\n\n            # === RPN Accuracy Calculation ===\n            predicted_classes = torch.argmax(logits, dim=1)\n            correct_rpn += (predicted_classes == targets_cls).sum().item()\n            total_rpn += targets_cls.numel()\n\n            # === DQN Training ===\n            state = features.view(features.size(0), -1).to(device)  \n            q_values = dqn(state)\n            predicted_actions = torch.argmax(q_values, dim=1)\n\n            # Generate Random Labels (For Testing)\n            true_labels = torch.randint(0, 2, (q_values.shape[0],), device=device)\n\n            loss_dqn = criterion_dqn(q_values, nn.functional.one_hot(true_labels, num_classes=2).float())\n\n            optimizer_dqn.zero_grad()  \n            loss_dqn.backward()\n            optimizer_dqn.step()\n\n            epoch_loss_dqn += loss_dqn.item()\n\n            # === DQN Accuracy Calculation ===\n            correct_dqn += (predicted_actions == true_labels).sum().item()\n            total_dqn += true_labels.numel()\n\n        # Compute Final Accuracy\n        rpn_accuracy = (correct_rpn / total_rpn) * 100\n        dqn_accuracy = (correct_dqn / total_dqn) * 100\n\n        print(f\"Epoch {epoch + 1}:\")\n        print(f\"   - RPN Loss = {epoch_loss_rpn:.4f}, Accuracy = {rpn_accuracy:.2f}%\")\n        print(f\"   - DQN Loss = {epoch_loss_dqn:.4f}, Accuracy = {dqn_accuracy:.2f}%\")\n\n# Train the model and track accuracy\ntrain_rpn_dqn()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T14:48:27.412566Z","iopub.execute_input":"2025-02-03T14:48:27.412917Z","iopub.status.idle":"2025-02-03T14:53:30.234657Z","shell.execute_reply.started":"2025-02-03T14:48:27.412877Z","shell.execute_reply":"2025-02-03T14:53:30.233465Z"}},"outputs":[{"name":"stderr","text":"Epoch 1/15: 100%|██████████| 5/5 [00:19<00:00,  3.98s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1:\n   - RPN Loss = 5.5939, Accuracy = 49.99%\n   - DQN Loss = 99.4157, Accuracy = 50.45%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/15: 100%|██████████| 5/5 [00:19<00:00,  3.94s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2:\n   - RPN Loss = 5.5868, Accuracy = 50.03%\n   - DQN Loss = 45.2924, Accuracy = 49.90%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/15: 100%|██████████| 5/5 [00:20<00:00,  4.11s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3:\n   - RPN Loss = 5.5961, Accuracy = 49.97%\n   - DQN Loss = 15.9947, Accuracy = 49.25%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/15: 100%|██████████| 5/5 [00:20<00:00,  4.10s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4:\n   - RPN Loss = 5.5925, Accuracy = 50.00%\n   - DQN Loss = 13.1527, Accuracy = 48.86%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/15: 100%|██████████| 5/5 [00:19<00:00,  3.98s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5:\n   - RPN Loss = 5.5914, Accuracy = 50.07%\n   - DQN Loss = 5.4800, Accuracy = 48.76%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/15: 100%|██████████| 5/5 [00:20<00:00,  4.02s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6:\n   - RPN Loss = 5.5930, Accuracy = 49.90%\n   - DQN Loss = 3.8844, Accuracy = 50.80%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/15: 100%|██████████| 5/5 [00:20<00:00,  4.06s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7:\n   - RPN Loss = 5.5869, Accuracy = 50.00%\n   - DQN Loss = 2.3039, Accuracy = 49.20%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/15: 100%|██████████| 5/5 [00:20<00:00,  4.07s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8:\n   - RPN Loss = 5.5876, Accuracy = 50.02%\n   - DQN Loss = 2.2150, Accuracy = 51.64%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/15: 100%|██████████| 5/5 [00:20<00:00,  4.04s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9:\n   - RPN Loss = 5.5888, Accuracy = 50.02%\n   - DQN Loss = 1.8610, Accuracy = 49.30%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/15: 100%|██████████| 5/5 [00:20<00:00,  4.01s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10:\n   - RPN Loss = 5.5952, Accuracy = 49.99%\n   - DQN Loss = 1.4265, Accuracy = 49.50%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11/15: 100%|██████████| 5/5 [00:20<00:00,  4.08s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 11:\n   - RPN Loss = 5.5864, Accuracy = 50.02%\n   - DQN Loss = 1.4659, Accuracy = 50.60%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12/15: 100%|██████████| 5/5 [00:20<00:00,  4.09s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 12:\n   - RPN Loss = 5.5908, Accuracy = 50.05%\n   - DQN Loss = 1.3650, Accuracy = 50.60%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 13/15: 100%|██████████| 5/5 [00:20<00:00,  4.03s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 13:\n   - RPN Loss = 5.5916, Accuracy = 50.02%\n   - DQN Loss = 1.3238, Accuracy = 49.90%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 14/15: 100%|██████████| 5/5 [00:20<00:00,  4.01s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 14:\n   - RPN Loss = 5.5881, Accuracy = 49.98%\n   - DQN Loss = 1.2856, Accuracy = 49.15%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 15/15: 100%|██████████| 5/5 [00:20<00:00,  4.03s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 15:\n   - RPN Loss = 5.5892, Accuracy = 49.94%\n   - DQN Loss = 1.2861, Accuracy = 51.29%\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":20}]}
